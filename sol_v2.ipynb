{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import cv2\n",
    "import os\n",
    "import tqdm\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class OralCancerDataset(Dataset):\n",
    "    \"\"\"__init__ and __len__ functions are the same as in TorchvisionDataset\"\"\"\n",
    "\n",
    "    def __init__(self, path_to_images, path_to_csv = None):\n",
    "        \n",
    "        # Passing the path to the train csv file reads the data from the csv with the labels\n",
    "        # If None is passes insted only the images in the image folder is loaded (wich is useful for the test set)\n",
    "        \n",
    "        self.path_to_images = path_to_images\n",
    "        self.path_to_csv = path_to_csv\n",
    "        self.transform= transforms.Compose([\n",
    "    transforms.Normalize(                      \n",
    "            mean=[0.485, 0.456, 0.406],                \n",
    "            std=[0.229, 0.224, 0.225]                  \n",
    "            ),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "        \n",
    "        if self.path_to_csv is not None:\n",
    "            self.df = pd.read_csv(self.path_to_csv)\n",
    "    \n",
    "    def __len__(self):\n",
    "        if self.path_to_csv:\n",
    "            return len(self.df)\n",
    "        else:\n",
    "            return len(glob.glob(self.path_to_images + '/*.jpg'))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if self.path_to_csv:\n",
    "            data = self.df.iloc[idx]\n",
    "            image = cv2.imread(os.path.join(self.path_to_images, data['Name']), -1)\n",
    "            label = data['Diagnosis']\n",
    "            \n",
    "            # You can input torchvision (or other) transforms and directly augment the data\n",
    "            # if self.transform:\n",
    "            #image = self.transform(image)\n",
    "            # ..\n",
    "            # image = transforms.functional.to_pil_image(image)\n",
    "            # image = transforms.functional.adjust_contrast(image, 2)\n",
    "            image = transforms.functional.to_tensor(image)\n",
    "            image = transforms.functional.normalize(image, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            \n",
    "            return image, label\n",
    "            \n",
    "        else:\n",
    "            name = 'image_' + str(idx) + '.jpg'\n",
    "            image = cv2.imread(os.path.join(self.path_to_images, name), -1)\n",
    "\n",
    "            # image = transforms.functional.to_pil_image(image)\n",
    "            # image = transforms.functional.adjust_contrast(image, 2)\n",
    "            image = transforms.functional.to_tensor(image)\n",
    "            image = transforms.functional.normalize(image, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            \n",
    "            return image, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG_4Cancer_Classification(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(VGG_4Cancer_Classification, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU())\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU())\n",
    "        self.layer4 = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU())\n",
    "        self.layer6 = nn.Sequential(\n",
    "            #nn.Dropout(0.2),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer7 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU()\n",
    "            )\n",
    "        self.layer8 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "            )\n",
    "        self.layer9 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer10 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer11 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer12 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer13 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.fc = nn.Sequential(\n",
    "            #nn.Dropout(0.5),\n",
    "            #nn.Linear(7*7*512, 4096),\n",
    "            nn.Linear(2*2*512, 4096),\n",
    "            nn.ReLU())\n",
    "        self.fc1 = nn.Sequential(\n",
    "            #nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU())\n",
    "        self.fc2= nn.Sequential(\n",
    "\n",
    "            nn.Linear(4096, num_classes))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = self.layer6(out)\n",
    "        out = self.layer7(out)\n",
    "        out = self.layer8(out)\n",
    "        out = self.layer9(out)\n",
    "        out = self.layer10(out)\n",
    "        out = self.layer11(out)\n",
    "        out = self.layer12(out)\n",
    "        out = self.layer13(out)\n",
    "        #print(out.shape)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        #print(out.shape)\n",
    "        out = self.fc(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_csv = 'Data/train.csv'\n",
    "path_to_train_images = path_to_val_images = 'Data/train'\n",
    "path_to_test_images = 'Data/test'\n",
    "\n",
    "df = pd.read_csv(path_to_csv)\n",
    "df['PatID'] = df['Name'].str[:7]\n",
    "\n",
    "val_df = df[df['Name'].str.contains(\"pat_025|pat_096|pat_081\")][['Name','Diagnosis']].copy()\n",
    "\n",
    "path_to_valcsv = 'Input/val_label.csv'\n",
    "val_df.to_csv(path_to_valcsv,index=False)\n",
    "\n",
    "train_df = df[~df['Name'].str.contains(\"pat_025|pat_096|pat_081\")][['Name','Diagnosis']].copy()\n",
    "\n",
    "path_to_traincsv = 'Input/train_label.csv'\n",
    "train_df.to_csv(path_to_traincsv,index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = OralCancerDataset(path_to_train_images, path_to_traincsv)\n",
    "\n",
    "val_dataset = OralCancerDataset(path_to_val_images, path_to_valcsv)\n",
    "\n",
    "test_dataset = OralCancerDataset(path_to_test_images, path_to_csv = None)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset,\n",
    "batch_size=32,\n",
    "shuffle=True,\n",
    "num_workers=0) \n",
    "\n",
    "val_dataloader= DataLoader(val_dataset,\n",
    "batch_size=32,\n",
    "shuffle=True,\n",
    "num_workers=0) \n",
    "\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20160"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(train_dataloader)*32 +\n",
    "len(val_dataloader)*32 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HYPERPARAMS\n",
    "\n",
    "num_classes = 2\n",
    "num_epochs = 20\n",
    "batch_size = 32\n",
    "learning_rate = 0.005\n",
    "l1_lambda = 0.001\n",
    "weight_decay_=0.005 #L2 Loss\n",
    "\n",
    "model = VGG_4Cancer_Classification(num_classes).to(device)\n",
    "\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) #torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = weight_decay_, momentum = 0.90)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchsummary\n",
    "# torchsummary.summary(model,(3,128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [01:55<00:00, 14.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Step [1667/2296], Accuracy: 72.9946; Loss: 1.0017\n",
      "Accuracy of the network on the 20160 validation images: 59.5223 % ; Loss - 0.6930\n",
      "Epoch [2/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [01:55<00:00, 14.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Step [1667/2296], Accuracy: 78.4411; Loss: 0.4667\n",
      "Accuracy of the network on the 20160 validation images: 54.1391 % ; Loss - 0.8404\n",
      "Epoch [3/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [01:56<00:00, 14.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Step [1667/2296], Accuracy: 80.8341; Loss: 0.4161\n",
      "Accuracy of the network on the 20160 validation images: 57.2578 % ; Loss - 0.9046\n",
      "Epoch [4/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [01:54<00:00, 14.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Step [1667/2296], Accuracy: 84.0603; Loss: 0.3586\n",
      "Accuracy of the network on the 20160 validation images: 54.4520 % ; Loss - 1.0984\n",
      "Epoch [5/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [01:54<00:00, 14.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Step [1667/2296], Accuracy: 85.6668; Loss: 0.3276\n",
      "Accuracy of the network on the 20160 validation images: 56.7115 % ; Loss - 1.1677\n",
      "Epoch [6/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [01:54<00:00, 14.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Step [1667/2296], Accuracy: 87.0857; Loss: 0.3051\n",
      "Accuracy of the network on the 20160 validation images: 58.2361 % ; Loss - 1.0521\n",
      "Epoch [7/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [01:54<00:00, 14.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Step [1667/2296], Accuracy: 87.9415; Loss: 0.2870\n",
      "Accuracy of the network on the 20160 validation images: 55.9170 % ; Loss - 1.0965\n",
      "Epoch [8/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [01:54<00:00, 14.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Step [1667/2296], Accuracy: 89.4336; Loss: 0.2558\n",
      "Accuracy of the network on the 20160 validation images: 58.6483 % ; Loss - 1.2569\n",
      "Epoch [9/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [01:54<00:00, 14.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Step [1667/2296], Accuracy: 90.3044; Loss: 0.2345\n",
      "Accuracy of the network on the 20160 validation images: 60.6446 % ; Loss - 1.3114\n",
      "Epoch [10/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [01:54<00:00, 14.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Step [1667/2296], Accuracy: 91.0551; Loss: 0.2174\n",
      "Accuracy of the network on the 20160 validation images: 63.9668 % ; Loss - 0.9341\n",
      "Epoch [11/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [01:54<00:00, 14.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Step [1667/2296], Accuracy: 91.8959; Loss: 0.2013\n",
      "Accuracy of the network on the 20160 validation images: 58.9611 % ; Loss - 1.4401\n",
      "Epoch [12/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [01:54<00:00, 14.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Step [1667/2296], Accuracy: 92.4890; Loss: 0.1885\n",
      "Accuracy of the network on the 20160 validation images: 60.4757 % ; Loss - 1.2285\n",
      "Epoch [13/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [01:54<00:00, 14.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Step [1667/2296], Accuracy: 93.0521; Loss: 0.1749\n",
      "Accuracy of the network on the 20160 validation images: 60.6049 % ; Loss - 1.4323\n",
      "Epoch [14/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [01:54<00:00, 14.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Step [1667/2296], Accuracy: 93.6695; Loss: 0.1601\n",
      "Accuracy of the network on the 20160 validation images: 58.8171 % ; Loss - 1.2754\n",
      "Epoch [15/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [01:54<00:00, 14.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Step [1667/2296], Accuracy: 93.9755; Loss: 0.1527\n",
      "Accuracy of the network on the 20160 validation images: 61.5136 % ; Loss - 1.9110\n",
      "Epoch [16/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [01:54<00:00, 14.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Step [1667/2296], Accuracy: 94.2007; Loss: 0.1473\n",
      "Accuracy of the network on the 20160 validation images: 60.8085 % ; Loss - 1.3624\n",
      "Epoch [17/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [01:54<00:00, 14.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Step [1667/2296], Accuracy: 94.6286; Loss: 0.1358\n",
      "Accuracy of the network on the 20160 validation images: 60.3566 % ; Loss - 1.4017\n",
      "Epoch [18/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [01:54<00:00, 14.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Step [1667/2296], Accuracy: 95.0208; Loss: 0.1288\n",
      "Accuracy of the network on the 20160 validation images: 66.5293 % ; Loss - 1.4017\n",
      "Epoch [19/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [01:54<00:00, 14.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Step [1667/2296], Accuracy: 92.3445; Loss: 0.1940\n",
      "Accuracy of the network on the 20160 validation images: 67.4331 % ; Loss - 1.2530\n",
      "Epoch [20/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [01:54<00:00, 14.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Step [1667/2296], Accuracy: 95.2273; Loss: 0.1236\n",
      "Accuracy of the network on the 20160 validation images: 58.8072 % ; Loss - 1.7241\n"
     ]
    }
   ],
   "source": [
    "#TRAINING\n",
    "\n",
    "total_step = len(train_dataloader)+len(val_dataloader)\n",
    "df_train={'Loss':[], 'Accuracy':[]}\n",
    "df_val={'Loss':[], 'Accuracy':[]}\n",
    "for epoch in range(num_epochs):\n",
    "    print ('Epoch [{}/{}]' \n",
    "                   .format(epoch+1, num_epochs))\n",
    "    i=0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loss_train=[]\n",
    "    for (images, labels) in tqdm.tqdm(train_dataloader):  \n",
    "        # Move tensors to the configured device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        images=images.permute(0,1,2,3)\n",
    "        # Forward pass\n",
    "        outputs = model(images.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_train.append(loss.item())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        #L1 loss\n",
    "       \n",
    "        # l1_norm = sum(abs(p).sum()\n",
    "        #           for p in model.parameters())\n",
    "\n",
    "        # loss = loss + l1_lambda * l1_norm\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        i=i+1\n",
    "\n",
    "    df_train['Loss'].append(np.mean(loss_train))\n",
    "    df_train['Accuracy'].append(100 * correct / total)\n",
    "    print ('Epoch [{}/{}], Step [{}/{}], Accuracy: {:0.4f}; Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step,100 * correct / total, np.mean(loss_train)))\n",
    "    \n",
    "    loss_val=[]\n",
    "    # Validation\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in val_dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            images=images.permute(0,1,2,3)\n",
    "            outputs = model(images.float())\n",
    "            loss_v = criterion(outputs, labels)\n",
    "            loss_val.append(loss_v.item())\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            del images, labels, outputs\n",
    "\n",
    "        df_val['Loss'].append(np.mean(loss_val))\n",
    "        df_val['Accuracy'].append(100 * correct / total)\n",
    "        print('Accuracy of the network on the {} validation images: {:.4f} % ; Loss - {:.4f}'.format(len(val_dataloader)*32, 100 * correct / total,np.mean(loss_val))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Inference/Trial_8/train.csv saved successfully!\n",
      "File Inference/Trial_8/val.csv saved successfully!\n"
     ]
    }
   ],
   "source": [
    "#SAVING EVAL DATA FOR INFERENCE\n",
    "train_summary = pd.DataFrame(df_train)\n",
    "\n",
    "tr_filename='Inference/Trial_8/'\n",
    "if not os.path.exists(tr_filename):\n",
    "    os.mkdir(tr_filename)\n",
    "train_summary.to_csv(tr_filename+'train.csv', index = False)\n",
    "print(\"File {} saved successfully!\".format(tr_filename+'train.csv'))\n",
    "\n",
    "val_summary = pd.DataFrame(df_val)\n",
    "val_filename='Inference/Trial_8/'\n",
    "val_summary.to_csv(val_filename+'val.csv', index = False)\n",
    "print(\"File {} saved successfully!\".format(val_filename+'val.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Predictions/test_preds_8.csv saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Test Prediction\n",
    "df={'Name':[], 'Diagnosis':[]}\n",
    "i=0\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, names in test_dataloader:\n",
    "        images = images.to(device)\n",
    "\n",
    "        images=images.permute(0,1,2,3)\n",
    "        outputs = model(images.float()).cpu()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        df['Name'].extend(names)\n",
    "        df['Diagnosis'].extend(predicted.detach().numpy())\n",
    "        i+=1\n",
    "        print('Test images {}/{} done.'.format(i*32,len(test_dataloader)*32),end='\\r') \n",
    "\n",
    "test_preds = pd.DataFrame(df)\n",
    "test_filename='Predictions/test_preds_8.csv'\n",
    "\n",
    "test_preds.to_csv(test_filename, index = False)\n",
    "print(\"File {} saved successfully!\".format(test_filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n",
      "Path: Model/final_model_8.pt\n"
     ]
    }
   ],
   "source": [
    "#SAVING MODEL DATA \n",
    "model_path=\"Model/final_model_8.pt\"\n",
    "torch.save(model,model_path)\n",
    "print(\"Model saved successfully!\\nPath: {}\".format(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
