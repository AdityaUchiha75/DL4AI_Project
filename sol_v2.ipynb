{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import cv2\n",
    "import os\n",
    "import tqdm\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class OralCancerDataset(Dataset):\n",
    "    \"\"\"__init__ and __len__ functions are the same as in TorchvisionDataset\"\"\"\n",
    "\n",
    "    def __init__(self, path_to_images, path_to_csv = None):\n",
    "        \n",
    "        # Passing the path to the train csv file reads the data from the csv with the labels\n",
    "        # If None is passes insted only the images in the image folder is loaded (wich is useful for the test set)\n",
    "        \n",
    "        self.path_to_images = path_to_images\n",
    "        self.path_to_csv = path_to_csv\n",
    "        self.transform= transforms.Compose([\n",
    "    transforms.Normalize(                      \n",
    "            mean=[0.485, 0.456, 0.406],                \n",
    "            std=[0.229, 0.224, 0.225]                  \n",
    "            ),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "        \n",
    "        if self.path_to_csv is not None:\n",
    "            self.df = pd.read_csv(self.path_to_csv)\n",
    "    \n",
    "    def __len__(self):\n",
    "        if self.path_to_csv:\n",
    "            return len(self.df)\n",
    "        else:\n",
    "            return len(glob.glob(self.path_to_images + '/*.jpg'))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if self.path_to_csv:\n",
    "            data = self.df.iloc[idx]\n",
    "            image = cv2.imread(os.path.join(self.path_to_images, data['Name']), -1)\n",
    "            label = data['Diagnosis']\n",
    "            \n",
    "            # You can input torchvision (or other) transforms and directly augment the data\n",
    "            # if self.transform:\n",
    "            #image = self.transform(image)\n",
    "            # ..\n",
    "            # image = transforms.functional.to_pil_image(image)\n",
    "            # image = transforms.functional.adjust_contrast(image, 2)\n",
    "            image = transforms.functional.to_tensor(image)\n",
    "            image = transforms.functional.normalize(image, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            \n",
    "            return image, label\n",
    "            \n",
    "        else:\n",
    "            name = 'image_' + str(idx) + '.jpg'\n",
    "            image = cv2.imread(os.path.join(self.path_to_images, name), -1)\n",
    "\n",
    "            # image = transforms.functional.to_pil_image(image)\n",
    "            # image = transforms.functional.adjust_contrast(image, 2)\n",
    "            image = transforms.functional.to_tensor(image)\n",
    "            image = transforms.functional.normalize(image, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            \n",
    "            return image, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG_4Cancer_Classification(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(VGG_4Cancer_Classification, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU())\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU())\n",
    "        self.layer4 = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU())\n",
    "        self.layer6 = nn.Sequential(\n",
    "            #nn.Dropout(0.2),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer7 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU()\n",
    "            )\n",
    "        self.layer8 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "            )\n",
    "        self.layer9 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer10 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer11 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer12 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer13 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.fc = nn.Sequential(\n",
    "            #nn.Dropout(0.5),\n",
    "            #nn.Linear(7*7*512, 4096),\n",
    "            nn.Linear(2*2*512, 4096),\n",
    "            nn.ReLU())\n",
    "        # self.fc1 = nn.Sequential(\n",
    "        #     nn.Dropout(0.5),\n",
    "        #     nn.Linear(32000, 4096),\n",
    "        #     nn.ReLU())\n",
    "        self.fc2= nn.Sequential(\n",
    "\n",
    "            nn.Linear(4096, num_classes))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = self.layer6(out)\n",
    "        out = self.layer7(out)\n",
    "        out = self.layer8(out)\n",
    "        out = self.layer9(out)\n",
    "        out = self.layer10(out)\n",
    "        out = self.layer11(out)\n",
    "        out = self.layer12(out)\n",
    "        out = self.layer13(out)\n",
    "        #print(out.shape)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        #print(out.shape)\n",
    "        out = self.fc(out)\n",
    "        #out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_csv = 'Data/train.csv'\n",
    "path_to_train_images = path_to_val_images = 'Data/train'\n",
    "path_to_test_images = 'Data/test'\n",
    "\n",
    "df = pd.read_csv(path_to_csv)\n",
    "df['PatID'] = df['Name'].str[:7]\n",
    "\n",
    "val_df = df[df['Name'].str.contains(\"pat_025|pat_096|pat_081\")][['Name','Diagnosis']].copy()\n",
    "\n",
    "path_to_valcsv = 'Input/val_label.csv'\n",
    "val_df.to_csv(path_to_valcsv,index=False)\n",
    "\n",
    "train_df = df[~df['Name'].str.contains(\"pat_025|pat_096|pat_081\")][['Name','Diagnosis']].copy()\n",
    "\n",
    "path_to_traincsv = 'Input/train_label.csv'\n",
    "train_df.to_csv(path_to_traincsv,index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = OralCancerDataset(path_to_train_images, path_to_traincsv)\n",
    "\n",
    "val_dataset = OralCancerDataset(path_to_val_images, path_to_valcsv)\n",
    "\n",
    "test_dataset = OralCancerDataset(path_to_test_images, path_to_csv = None)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset,\n",
    "batch_size=32,\n",
    "shuffle=True,\n",
    "num_workers=0) \n",
    "\n",
    "val_dataloader= DataLoader(val_dataset,\n",
    "batch_size=32,\n",
    "shuffle=True,\n",
    "num_workers=0) \n",
    "\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20160"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(train_dataloader)*32 +\n",
    "len(val_dataloader)*32 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HYPERPARAMS\n",
    "\n",
    "num_classes = 2\n",
    "num_epochs = 60\n",
    "batch_size = 32\n",
    "learning_rate = 0.005\n",
    "l1_lambda = 0.001\n",
    "weight_decay_=0.005 #L2 Loss\n",
    "\n",
    "model = VGG_4Cancer_Classification(num_classes).to(device)\n",
    "\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) #torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = weight_decay_, momentum = 0.90)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 128, 128]             896\n",
      "       BatchNorm2d-2         [-1, 32, 128, 128]              64\n",
      "              ReLU-3         [-1, 32, 128, 128]               0\n",
      "            Conv2d-4         [-1, 32, 128, 128]           9,248\n",
      "       BatchNorm2d-5         [-1, 32, 128, 128]              64\n",
      "              ReLU-6         [-1, 32, 128, 128]               0\n",
      "         MaxPool2d-7           [-1, 32, 64, 64]               0\n",
      "            Conv2d-8           [-1, 64, 64, 64]          18,496\n",
      "       BatchNorm2d-9           [-1, 64, 64, 64]             128\n",
      "             ReLU-10           [-1, 64, 64, 64]               0\n",
      "           Conv2d-11           [-1, 64, 64, 64]          36,928\n",
      "      BatchNorm2d-12           [-1, 64, 64, 64]             128\n",
      "             ReLU-13           [-1, 64, 64, 64]               0\n",
      "        MaxPool2d-14           [-1, 64, 32, 32]               0\n",
      "           Conv2d-15          [-1, 128, 32, 32]          73,856\n",
      "      BatchNorm2d-16          [-1, 128, 32, 32]             256\n",
      "             ReLU-17          [-1, 128, 32, 32]               0\n",
      "           Conv2d-18          [-1, 128, 32, 32]         147,584\n",
      "      BatchNorm2d-19          [-1, 128, 32, 32]             256\n",
      "             ReLU-20          [-1, 128, 32, 32]               0\n",
      "        MaxPool2d-21          [-1, 128, 16, 16]               0\n",
      "           Conv2d-22          [-1, 256, 16, 16]         295,168\n",
      "      BatchNorm2d-23          [-1, 256, 16, 16]             512\n",
      "             ReLU-24          [-1, 256, 16, 16]               0\n",
      "           Conv2d-25          [-1, 256, 16, 16]         590,080\n",
      "      BatchNorm2d-26          [-1, 256, 16, 16]             512\n",
      "             ReLU-27          [-1, 256, 16, 16]               0\n",
      "        MaxPool2d-28            [-1, 256, 8, 8]               0\n",
      "           Conv2d-29            [-1, 512, 8, 8]       1,180,160\n",
      "      BatchNorm2d-30            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-31            [-1, 512, 8, 8]               0\n",
      "           Conv2d-32            [-1, 512, 8, 8]       2,359,808\n",
      "      BatchNorm2d-33            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-34            [-1, 512, 8, 8]               0\n",
      "        MaxPool2d-35            [-1, 512, 4, 4]               0\n",
      "           Conv2d-36            [-1, 512, 4, 4]       2,359,808\n",
      "      BatchNorm2d-37            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-38            [-1, 512, 4, 4]               0\n",
      "           Conv2d-39            [-1, 512, 4, 4]       2,359,808\n",
      "      BatchNorm2d-40            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-41            [-1, 512, 4, 4]               0\n",
      "           Conv2d-42            [-1, 512, 4, 4]       2,359,808\n",
      "      BatchNorm2d-43            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-44            [-1, 512, 4, 4]               0\n",
      "        MaxPool2d-45            [-1, 512, 2, 2]               0\n",
      "           Linear-46                 [-1, 4096]       8,392,704\n",
      "             ReLU-47                 [-1, 4096]               0\n",
      "           Linear-48                    [-1, 2]           8,194\n",
      "================================================================\n",
      "Total params: 20,199,586\n",
      "Trainable params: 20,199,586\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 49.08\n",
      "Params size (MB): 77.06\n",
      "Estimated Total Size (MB): 126.32\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# import torchsummary\n",
    "# torchsummary.summary(model,(3,128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [02:09<00:00, 12.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Step [1667/2296], Accuracy: 75.1905; Loss: 0.5114\n",
      "Accuracy of the network on the 20160 validation images: 61.9357 % ; Loss - 0.8294\n",
      "Epoch [2/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [02:10<00:00, 12.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Step [1667/2296], Accuracy: 81.4478; Loss: 0.4020\n",
      "Accuracy of the network on the 20160 validation images: 59.9096 % ; Loss - 0.9914\n",
      "Epoch [3/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [02:08<00:00, 12.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Step [1667/2296], Accuracy: 83.7863; Loss: 0.3667\n",
      "Accuracy of the network on the 20160 validation images: 61.6030 % ; Loss - 0.9475\n",
      "Epoch [4/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [02:07<00:00, 13.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Step [1667/2296], Accuracy: 84.9818; Loss: 0.3441\n",
      "Accuracy of the network on the 20160 validation images: 61.1164 % ; Loss - 1.0084\n",
      "Epoch [5/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [02:11<00:00, 12.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Step [1667/2296], Accuracy: 85.8282; Loss: 0.3280\n",
      "Accuracy of the network on the 20160 validation images: 61.8265 % ; Loss - 1.0572\n",
      "Epoch [6/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [02:11<00:00, 12.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Step [1667/2296], Accuracy: 86.7892; Loss: 0.3122\n",
      "Accuracy of the network on the 20160 validation images: 60.1480 % ; Loss - 1.1556\n",
      "Epoch [7/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [02:12<00:00, 12.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Step [1667/2296], Accuracy: 87.5136; Loss: 0.2958\n",
      "Accuracy of the network on the 20160 validation images: 60.7489 % ; Loss - 1.0799\n",
      "Epoch [8/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [02:11<00:00, 12.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Step [1667/2296], Accuracy: 87.5868; Loss: 0.2932\n",
      "Accuracy of the network on the 20160 validation images: 62.0102 % ; Loss - 1.0392\n",
      "Epoch [9/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [02:11<00:00, 12.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Step [1667/2296], Accuracy: 88.4295; Loss: 0.2752\n",
      "Accuracy of the network on the 20160 validation images: 57.2379 % ; Loss - 1.3131\n",
      "Epoch [10/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [02:11<00:00, 12.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Step [1667/2296], Accuracy: 89.1539; Loss: 0.2594\n",
      "Accuracy of the network on the 20160 validation images: 58.2857 % ; Loss - 1.4021\n",
      "Epoch [11/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [02:10<00:00, 12.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Step [1667/2296], Accuracy: 89.6119; Loss: 0.2490\n",
      "Accuracy of the network on the 20160 validation images: 63.9619 % ; Loss - 1.2086\n",
      "Epoch [12/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [02:10<00:00, 12.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Step [1667/2296], Accuracy: 90.1618; Loss: 0.2395\n",
      "Accuracy of the network on the 20160 validation images: 61.7421 % ; Loss - 1.1696\n",
      "Epoch [13/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [02:10<00:00, 12.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Step [1667/2296], Accuracy: 90.3776; Loss: 0.2325\n",
      "Accuracy of the network on the 20160 validation images: 60.3317 % ; Loss - 1.1507\n",
      "Epoch [14/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [02:14<00:00, 12.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Step [1667/2296], Accuracy: 90.7473; Loss: 0.2240\n",
      "Accuracy of the network on the 20160 validation images: 59.1151 % ; Loss - 1.3297\n",
      "Epoch [15/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [02:10<00:00, 12.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Step [1667/2296], Accuracy: 91.3104; Loss: 0.2128\n",
      "Accuracy of the network on the 20160 validation images: 58.6085 % ; Loss - 1.4710\n",
      "Epoch [16/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [02:10<00:00, 12.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Step [1667/2296], Accuracy: 91.6670; Loss: 0.2025\n",
      "Accuracy of the network on the 20160 validation images: 59.8550 % ; Loss - 1.5319\n",
      "Epoch [17/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [02:10<00:00, 12.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Step [1667/2296], Accuracy: 92.2601; Loss: 0.1904\n",
      "Accuracy of the network on the 20160 validation images: 59.7954 % ; Loss - 1.3013\n",
      "Epoch [18/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [02:12<00:00, 12.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Step [1667/2296], Accuracy: 92.3858; Loss: 0.1862\n",
      "Accuracy of the network on the 20160 validation images: 63.2617 % ; Loss - 1.2780\n",
      "Epoch [19/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [02:11<00:00, 12.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Step [1667/2296], Accuracy: 92.8344; Loss: 0.1764\n",
      "Accuracy of the network on the 20160 validation images: 60.4013 % ; Loss - 1.4088\n",
      "Epoch [20/20]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [02:12<00:00, 12.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Step [1667/2296], Accuracy: 93.2022; Loss: 0.1703\n",
      "Accuracy of the network on the 20160 validation images: 58.1914 % ; Loss - 1.7395\n"
     ]
    }
   ],
   "source": [
    "#TRAINING\n",
    "\n",
    "total_step = len(train_dataloader)+len(val_dataloader)\n",
    "df_train={'Loss':[], 'Accuracy':[]}\n",
    "df_val={'Loss':[], 'Accuracy':[]}\n",
    "for epoch in range(num_epochs):\n",
    "    print ('Epoch [{}/{}]' \n",
    "                   .format(epoch+1, num_epochs))\n",
    "    i=0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loss_train=[]\n",
    "    for (images, labels) in tqdm.tqdm(train_dataloader):  \n",
    "        # Move tensors to the configured device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        images=images.permute(0,1,2,3)\n",
    "        # Forward pass\n",
    "        outputs = model(images.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_train.append(loss.item())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        #L1 loss\n",
    "       \n",
    "        # l1_norm = sum(abs(p).sum()\n",
    "        #           for p in model.parameters())\n",
    "\n",
    "        # loss = loss + l1_lambda * l1_norm\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        i=i+1\n",
    "\n",
    "    df_train['Loss'].append(np.mean(loss_train))\n",
    "    df_train['Accuracy'].append(100 * correct / total)\n",
    "    print ('Epoch [{}/{}], Step [{}/{}], Accuracy: {:0.4f}; Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step,100 * correct / total, np.mean(loss_train)))\n",
    "    \n",
    "    loss_val=[]\n",
    "    # Validation\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in val_dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            images=images.permute(0,1,2,3)\n",
    "            outputs = model(images.float())\n",
    "            loss_v = criterion(outputs, labels)\n",
    "            loss_val.append(loss_v.item())\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            del images, labels, outputs\n",
    "\n",
    "        df_val['Loss'].append(np.mean(loss_val))\n",
    "        df_val['Accuracy'].append(100 * correct / total)\n",
    "        print('Accuracy of the network on the {} validation images: {:.4f} % ; Loss - {:.4f}'.format(len(val_dataloader)*32, 100 * correct / total,np.mean(loss_val))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Inference/Trial_7/train.csv saved successfully!\n",
      "File Inference/Trial_7/val.csv saved successfully!\n"
     ]
    }
   ],
   "source": [
    "#SAVING EVAL DATA FOR INFERENCE\n",
    "train_summary = pd.DataFrame(df_train)\n",
    "\n",
    "tr_filename='Inference/Trial_8/'\n",
    "if not os.path.exists(tr_filename):\n",
    "    os.mkdir(tr_filename)\n",
    "train_summary.to_csv(tr_filename+'train.csv', index = False)\n",
    "print(\"File {} saved successfully!\".format(tr_filename+'train.csv'))\n",
    "\n",
    "val_summary = pd.DataFrame(df_val)\n",
    "val_filename='Inference/Trial_8/'\n",
    "val_summary.to_csv(val_filename+'val.csv', index = False)\n",
    "print(\"File {} saved successfully!\".format(val_filename+'val.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Predictions/test_preds_7.csv saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Test Prediction\n",
    "df={'Name':[], 'Diagnosis':[]}\n",
    "i=0\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, names in test_dataloader:\n",
    "        images = images.to(device)\n",
    "\n",
    "        images=images.permute(0,1,2,3)\n",
    "        outputs = model(images.float()).cpu()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        df['Name'].extend(names)\n",
    "        df['Diagnosis'].extend(predicted.detach().numpy())\n",
    "        i+=1\n",
    "        print('Test images {}/{} done.'.format(i*32,len(test_dataloader)*32),end='\\r') \n",
    "\n",
    "test_preds = pd.DataFrame(df)\n",
    "test_filename='Predictions/test_preds_8.csv'\n",
    "\n",
    "test_preds.to_csv(test_filename, index = False)\n",
    "print(\"File {} saved successfully!\".format(test_filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n",
      "Path: Model/final_model_7.pt\n"
     ]
    }
   ],
   "source": [
    "#SAVING MODEL DATA \n",
    "model_path=\"Model/final_model_7.pt\"\n",
    "torch.save(model,model_path)\n",
    "print(\"Model saved successfully!\\nPath: {}\".format(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
