{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import cv2\n",
    "import os\n",
    "import tqdm\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class OralCancerDataset(Dataset):\n",
    "    \"\"\"__init__ and __len__ functions are the same as in TorchvisionDataset\"\"\"\n",
    "\n",
    "    def __init__(self, path_to_images, path_to_csv = None, validation=False, val_ratio=1.0):\n",
    "        \n",
    "        # Passing the path to the train csv file reads the data from the csv with the labels\n",
    "        # If None is passes insted only the images in the image folder is loaded (wich is useful for the test set)\n",
    "        \n",
    "        self.path_to_images = path_to_images\n",
    "        self.path_to_csv = path_to_csv\n",
    "        self.v=validation\n",
    "        self.v_r=val_ratio\n",
    "\n",
    "        if self.path_to_csv is not None:\n",
    "            dat=pd.read_csv(self.path_to_csv)\n",
    "            dat=shuffle(dat)\n",
    "            dat.reset_index(inplace=True, drop=True)\n",
    "            val,tr=np.split(dat,[int(len(dat)*val_ratio)]) #train val split\n",
    "            \n",
    "            if self.v==False:\n",
    "                #self.df = pd.read_csv(self.path_to_csv)\n",
    "                self.df=tr\n",
    "\n",
    "            elif self.v==True:\n",
    "                self.df=val\n",
    "    \n",
    "    def __len__(self):\n",
    "        if self.path_to_csv:\n",
    "            return len(self.df)\n",
    "        else:\n",
    "            return len(glob.glob(self.path_to_images + '/*.jpg'))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if self.path_to_csv:\n",
    "            data = self.df.iloc[idx]\n",
    "            #print(data['Name'])\n",
    "            image = cv2.imread(os.path.join(self.path_to_images, data['Name']), -1)\n",
    "            label = data['Diagnosis']\n",
    "            \n",
    "            # You can input torchvision (or other) transforms and directly augment the data\n",
    "            # if self.transform:\n",
    "            #    image = self.transform(image)\n",
    "            # ..\n",
    "            \n",
    "            return image, label\n",
    "            \n",
    "        else:\n",
    "            name = 'image_' + str(idx) + '.jpg'\n",
    "            image = cv2.imread(os.path.join(self.path_to_images, name), -1)\n",
    "            \n",
    "            return image, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG_4Cancer_Classification(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(VGG_4Cancer_Classification, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU())\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU())\n",
    "        self.layer4 = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU())\n",
    "        self.layer6 = nn.Sequential(\n",
    "            #nn.Dropout(0.2),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        # self.layer7 = nn.Sequential(\n",
    "        #     nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "        #     nn.BatchNorm2d(256),\n",
    "        #     nn.ReLU()\n",
    "        #     )\n",
    "        # self.layer8 = nn.Sequential(\n",
    "        #     nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "        #     nn.BatchNorm2d(256),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        #     )\n",
    "        # self.layer9 = nn.Sequential(\n",
    "        #     nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "        #     nn.BatchNorm2d(512),\n",
    "        #     nn.ReLU())\n",
    "        # self.layer10 = nn.Sequential(\n",
    "        #     nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "        #     nn.BatchNorm2d(512),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        # self.layer11 = nn.Sequential(\n",
    "        #     nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "        #     nn.BatchNorm2d(512),\n",
    "        #     nn.ReLU())\n",
    "        # self.layer12 = nn.Sequential(\n",
    "        #     nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "        #     nn.BatchNorm2d(512),\n",
    "        #     nn.ReLU())\n",
    "        # self.layer13 = nn.Sequential(\n",
    "        #     nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "        #     nn.BatchNorm2d(512),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            #nn.Linear(7*7*512, 4096),\n",
    "            nn.Linear(16*16*128, 4096),\n",
    "            nn.ReLU())\n",
    "        # self.fc1 = nn.Sequential(\n",
    "        #     nn.Dropout(0.5),\n",
    "        #     nn.Linear(32000, 4096),\n",
    "        #     nn.ReLU())\n",
    "        self.fc2= nn.Sequential(\n",
    "\n",
    "            nn.Linear(4096, num_classes))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = self.layer6(out)\n",
    "        # out = self.layer7(out)\n",
    "        # out = self.layer8(out)\n",
    "        # out = self.layer9(out)\n",
    "        # out = self.layer10(out)\n",
    "        # out = self.layer11(out)\n",
    "        # out = self.layer12(out)\n",
    "        # out = self.layer13(out)\n",
    "        #print(out.shape)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        #print(out.shape)\n",
    "        out = self.fc(out)\n",
    "        #out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_csv = 'Data/train.csv'\n",
    "path_to_train_images = 'Data/train'\n",
    "path_to_test_images = 'Data/test'\n",
    "\n",
    "\n",
    "train_dataset = OralCancerDataset(path_to_train_images, path_to_csv, validation=False, val_ratio=0.3)\n",
    "val_dataset = OralCancerDataset(path_to_train_images, path_to_csv, validation=True, val_ratio=0.3)\n",
    "\n",
    "test_dataset = OralCancerDataset(path_to_test_images)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset,\n",
    "batch_size=32,\n",
    "shuffle=True,\n",
    "num_workers=0 ) #* (1+torch.cuda.device_count()))\n",
    "\n",
    "val_dataloader= DataLoader(val_dataset,\n",
    "batch_size=32,\n",
    "shuffle=True,\n",
    "num_workers=0 ) #* (1+torch.cuda.device_count()))\n",
    "\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=0 ) #* (1+torch.cuda.device_count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14688"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(train_dataloader)*32 +\n",
    "len(val_dataloader)*32 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HYPERPARAMS\n",
    "\n",
    "num_classes = 2\n",
    "num_epochs = 25\n",
    "batch_size = 32\n",
    "learning_rate = 0.005\n",
    "l1_lambda = 0.001\n",
    "weight_decay_=0.001 #L2 Loss\n",
    "\n",
    "model = VGG_4Cancer_Classification(num_classes).to(device)\n",
    "\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = weight_decay_, momentum = 0.95)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchsummary\n",
    "# torchsummary.summary(model,(3,128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING\n",
    "\n",
    "total_step = len(train_dataloader)+len(val_dataloader)\n",
    "df_train={'Loss':[], 'Accuracy':[]}\n",
    "df_val={'Loss':[], 'Accuracy':[]}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print ('Epoch [{}/{}]' \n",
    "                   .format(epoch+1, num_epochs))\n",
    "    i=0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for (images, labels) in tqdm.tqdm(train_dataloader):  \n",
    "        # Move tensors to the configured device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        images=images.permute(0,3,1,2)\n",
    "        # Forward pass\n",
    "        outputs = model(images.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        #L1 loss\n",
    "       \n",
    "        l1_norm = sum(abs(p).sum()\n",
    "                  for p in model.parameters())\n",
    "\n",
    "        loss = loss + l1_lambda * l1_norm\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        i=i+1\n",
    "\n",
    "    df_train['Loss'].append(loss.item())\n",
    "    df_train['Accuracy'].append(100 * correct / total)\n",
    "    print ('Epoch [{}/{}], Step [{}/{}], Accuracy: {:0.4f}; Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step,100 * correct / total, loss.item()))\n",
    "            \n",
    "    # Validation\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in val_dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            images=images.permute(0,3,1,2)\n",
    "            outputs = model(images.float())\n",
    "            loss_val = criterion(outputs, labels)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            del images, labels, outputs\n",
    "\n",
    "        df_val['Loss'].append(loss_val.item())\n",
    "        df_val['Accuracy'].append(100 * correct / total)\n",
    "        print('Accuracy of the network on the {} validation images: {:.4f} % ; Loss - {:.4f}'.format(len(val_dataloader)*32, 100 * correct / total,loss_val.item())) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVING EVAL DATA FOR INFERENCE\n",
    "train_summary = pd.DataFrame(df_train)\n",
    "tr_filename='Inference/Trial_2/train.csv'\n",
    "train_summary.to_csv(tr_filename, index = False)\n",
    "print(\"File {} saved successfully!\".format(tr_filename))\n",
    "\n",
    "val_summary = pd.DataFrame(df_val)\n",
    "val_filename='Inference/Trial_2/val.csv'\n",
    "val_summary.to_csv(val_filename, index = False)\n",
    "print(\"File {} saved successfully!\".format(val_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Prediction\n",
    "df={'Name':[], 'Diagnosis':[]}\n",
    "i=0\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, names in test_dataloader:\n",
    "        images = images.to(device)\n",
    "\n",
    "        images=images.permute(0,3,1,2)\n",
    "        outputs = model(images.float()).cpu()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        df['Name'].extend(names)\n",
    "        df['Diagnosis'].extend(predicted.detach().numpy())\n",
    "        i+=1\n",
    "        print('Test images {}/{} done.'.format(i*32,len(test_dataloader)*32),end='\\r') \n",
    "\n",
    "test_preds = pd.DataFrame(df)\n",
    "test_filename='test_preds_2.csv'\n",
    "\n",
    "test_preds.to_csv(test_filename, index = False)\n",
    "print(\"File {} saved successfully!\".format(test_filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVING MODEL DATA \n",
    "model_path=\"Model/final_model_2.pt\"\n",
    "torch.save(model,model_path)\n",
    "print(\"Model saved successfully!\\nPath: {}\".format(model_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
